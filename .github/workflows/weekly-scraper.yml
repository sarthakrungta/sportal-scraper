name: Weekly Cricket Data Scraper

on:
  push:
    branches:
      - main # or your default branch name

  schedule:
    # Runs at 11:00 AM UTC on Thursdays
    - cron: "0 11 * * 4"

    # Runs at 6:00 AM UTC on Fridays
    - cron: "0 6 * * 5"

    # Runs at 11:00 AM UTC on Fridays
    - cron: "0 11 * * 5"

  workflow_dispatch: # Allows manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.x"

      - name: Setup Chrome
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable

      - name: Get Chrome Version
        run: |
          echo "CHROME_VERSION=$(google-chrome --version | awk '{print $3}')" >> $GITHUB_ENV

      - name: Install Matching ChromeDriver
        run: |
          wget https://chromedriver.storage.googleapis.com/$CHROME_VERSION/chromedriver_linux64.zip
          unzip chromedriver_linux64.zip
          sudo mv chromedriver /usr/local/bin/

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install psycopg2-binary selenium beautifulsoup4 webdriver-manager

      - name: Run scraper
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: python main.py
